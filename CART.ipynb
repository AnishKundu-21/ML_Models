{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Importing Necessary Libraries and Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import graphviz\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('ObesityDataSet.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Bluiding Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Node class\n",
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value  # For leaf nodes, stores the class label\n",
    "\n",
    "# Define the DecisionTreeCART class\n",
    "class DecisionTreeCART:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_classes_ = len(np.unique(y))\n",
    "        self.n_features_ = X.shape[1]\n",
    "        self.tree_ = self._grow_tree(X, y)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "\n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or n_labels == 1:\n",
    "            leaf_value = Counter(y).most_common(1)[0][0]\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        best_gini = np.inf\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "\n",
    "        for feature in range(n_features):\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            for threshold in thresholds:\n",
    "                left_indices = np.where(X[:, feature] <= threshold)[0]\n",
    "                right_indices = np.where(X[:, feature] > threshold)[0]\n",
    "\n",
    "                gini_left = self._gini(y[left_indices])\n",
    "                gini_right = self._gini(y[right_indices])\n",
    "                gini = (len(left_indices) / n_samples) * gini_left + (len(right_indices) / n_samples) * gini_right\n",
    "\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        if best_gini == np.inf:\n",
    "            leaf_value = Counter(y).most_common(1)[0][0]\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        indices_left = np.where(X[:, best_feature] <= best_threshold)[0]\n",
    "        indices_right = np.where(X[:, best_feature] > best_threshold)[0]\n",
    "\n",
    "        left_child = self._grow_tree(X[indices_left], y[indices_left], depth + 1)\n",
    "        right_child = self._grow_tree(X[indices_right], y[indices_right], depth + 1)\n",
    "\n",
    "        return Node(feature=best_feature, threshold=best_threshold, left=left_child, right=right_child)\n",
    "\n",
    "    def _gini(self, y):\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / len(y)\n",
    "        gini = 1 - np.sum(probabilities ** 2)\n",
    "        return gini\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._predict(x, self.tree_) for x in X]\n",
    "\n",
    "    def _predict(self, x, tree):\n",
    "        if tree.value is not None:\n",
    "            return tree.value\n",
    "\n",
    "        if x[tree.feature] <= tree.threshold:\n",
    "            return self._predict(x, tree.left)\n",
    "        else:\n",
    "            return self._predict(x, tree.right)\n",
    "\n",
    "    def _export_to_graphviz(self, node, dot, feature_names):\n",
    "        if node is None:\n",
    "            return\n",
    "        if node.left is not None:\n",
    "            if node.left.value is not None:\n",
    "                dot.node(str(id(node.left)), label=str(node.left.value))\n",
    "            else:\n",
    "                dot.node(str(id(node.left)), label=str(feature_names[node.feature]) + \" <= \" + str(node.threshold))\n",
    "            dot.edge(str(id(node)), str(id(node.left)))\n",
    "            self._export_to_graphviz(node.left, dot, feature_names)\n",
    "        if node.right is not None:\n",
    "            if node.right.value is not None:\n",
    "                dot.node(str(id(node.right)), label=str(node.right.value))\n",
    "            else:\n",
    "                dot.node(str(id(node.right)), label=str(feature_names[node.feature]) + \" > \" + str(node.threshold))\n",
    "            dot.edge(str(id(node)), str(id(node.right)))\n",
    "            self._export_to_graphviz(node.right, dot, feature_names)\n",
    "\n",
    "    def export_graphviz(self, feature_names):\n",
    "        dot = graphviz.Digraph()\n",
    "        if self.tree_.value is not None:\n",
    "            dot.node(str(id(self.tree_)), label=str(self.tree_.value))\n",
    "        else:\n",
    "            dot.node(str(id(self.tree_)), label=str(feature_names[self.tree_.feature]) + \" <= \" + str(self.tree_.threshold))\n",
    "        self._export_to_graphviz(self.tree_, dot, feature_names)\n",
    "        return dot\n",
    "\n",
    "# Prepare features and target variable\n",
    "X = data.drop(['NObeyesdad'], axis=1).values\n",
    "y = data['NObeyesdad'].values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the decision tree model\n",
    "tree = DecisionTreeCART(max_depth=5)\n",
    "tree.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Testing Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's classify a new sample\n",
    "test_data = pd.DataFrame([\n",
    "    ['Male', 25, 1.80, 80, 'no', 'yes', 3, 3, 'Always', 'no', 2, 'no', 1, 0, 'Sometimes', 'Public_Transportation'],\n",
    "    ['Female', 30, 1.65, 70, 'yes', 'no', 2, 2, 'Sometimes', 'no', 1, 'yes', 0, 0, 'Sometimes', 'Public_Transportation'],\n",
    "    ['Male', 35, 1.70, 90, 'yes', 'yes', 3, 1, 'Always', 'no', 3, 'no', 2, 1, 'Frequently', 'Automobile'],\n",
    "    ['Female', 40, 1.60, 60, 'no', 'no', 2, 2, 'Sometimes', 'no', 2, 'no', 0, 0, 'Sometimes', 'Public_Transportation']\n",
    "], columns=data.drop(['NObeyesdad'], axis=1).columns)  # Use columns from data.drop\n",
    "\n",
    "# Predict the label of the new sample\n",
    "predicted_class = tree.predict(test_data.values)  # Pass values instead of DataFrame\n",
    "print(\"Predicted class:\", predicted_class)\n",
    "\n",
    "# Predictions\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy_percentage = accuracy * 100\n",
    "print(\"Accuracy:\", accuracy_percentage, \"%\")\n",
    "\n",
    "# Export the decision tree as a graph\n",
    "dot = tree.export_graphviz(feature_names=data.columns[:-1])\n",
    "\n",
    "# Save and display the decision tree\n",
    "dot.render(\"decision_tree_CART\", format=\"pdf\", cleanup=True, view=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
